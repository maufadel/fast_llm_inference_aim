{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:28:37.252967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746707317.271765  315389 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746707317.277190  315389 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746707317.294167  315389 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707317.294182  315389 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707317.294184  315389 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707317.294186  315389 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:28:37.299847: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:28:40 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-08 12:28:40 [__init__.py:239] Automatically detected platform cuda.\n",
      "[2025-05-08 12:28:43,339] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Running benchmark for gemma-2-9b-it with vllm on summarization\n",
      "INFO 05-08 12:29:01 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 12:29:01 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 05-08 12:29:03 [utils.py:2382] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 05-08 12:29:08 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:29:08.954228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746707348.971797  315669 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746707348.977132  315669 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746707348.990949  315669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707348.990967  315669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707348.990969  315669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707348.990970  315669 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:29:08.995071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:29:15 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:29:15 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x72068a0af550>\n",
      "INFO 05-08 12:29:15 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:29:15 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:29:16 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:29:16 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-9b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.03it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.24s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:29:21 [loader.py:458] Loading weights took 4.94 seconds\n",
      "INFO 05-08 12:29:21 [gpu_model_runner.py:1347] Model loading took 17.2181 GiB and 5.201648 seconds\n",
      "INFO 05-08 12:29:33 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/2fc7af7ba1/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:29:33 [backends.py:430] Dynamo bytecode transform time: 12.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:W0508 12:29:36.124000 315669 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:29:39 [backends.py:136] Cache the graph of shape None for later use\n",
      "INFO 05-08 12:30:37 [backends.py:148] Compiling a graph for general shape takes 61.96 s\n",
      "INFO 05-08 12:31:03 [monitor.py:33] torch.compile takes 74.06 s in total\n",
      "ERROR 05-08 12:31:04 [core.py:396] EngineCore failed to start.\n",
      "ERROR 05-08 12:31:04 [core.py:396] Traceback (most recent call last):\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "ERROR 05-08 12:31:04 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 05-08 12:31:04 [core.py:396]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "ERROR 05-08 12:31:04 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "ERROR 05-08 12:31:04 [core.py:396]     self._initialize_kv_caches(vllm_config)\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "ERROR 05-08 12:31:04 [core.py:396]     kv_cache_configs = [\n",
      "ERROR 05-08 12:31:04 [core.py:396]                        ^\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "ERROR 05-08 12:31:04 [core.py:396]     get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "ERROR 05-08 12:31:04 [core.py:396]     check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "ERROR 05-08 12:31:04 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "ERROR 05-08 12:31:04 [core.py:396]     raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ERROR 05-08 12:31:04 [core.py:396] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 400, in run_engine_core\n",
      "    raise e\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "    self._initialize_kv_caches(vllm_config)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "    kv_cache_configs = [\n",
      "                       ^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "    get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "    check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "    raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n",
      "[rank0]:[W508 12:31:06.498267908 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed: gemma-2-9b-it | vllm | summarization -- Engine core initialization failed. See root cause above.\n",
      "Running benchmark for gemma-2-9b-it with vllm on qa\n",
      "INFO 05-08 12:31:08 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 12:31:08 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:31:15 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:31:16.115219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746707476.132323  316473 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746707476.137488  316473 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746707476.151664  316473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707476.151683  316473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707476.151686  316473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707476.151688  316473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:31:16.155845: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:31:22 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:31:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7e3d2246c890>\n",
      "INFO 05-08 12:31:23 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:31:23 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:31:23 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:31:23 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-9b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.23it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.28s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.26s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:31:28 [loader.py:458] Loading weights took 5.01 seconds\n",
      "INFO 05-08 12:31:29 [gpu_model_runner.py:1347] Model loading took 17.2181 GiB and 5.352218 seconds\n",
      "INFO 05-08 12:31:42 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/2fc7af7ba1/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:31:42 [backends.py:430] Dynamo bytecode transform time: 13.35 s\n",
      "INFO 05-08 12:31:55 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 11.470 s\n",
      "INFO 05-08 12:32:04 [monitor.py:33] torch.compile takes 13.35 s in total\n",
      "ERROR 05-08 12:32:05 [core.py:396] EngineCore failed to start.\n",
      "ERROR 05-08 12:32:05 [core.py:396] Traceback (most recent call last):\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "ERROR 05-08 12:32:05 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 05-08 12:32:05 [core.py:396]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "ERROR 05-08 12:32:05 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "ERROR 05-08 12:32:05 [core.py:396]     self._initialize_kv_caches(vllm_config)\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "ERROR 05-08 12:32:05 [core.py:396]     kv_cache_configs = [\n",
      "ERROR 05-08 12:32:05 [core.py:396]                        ^\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "ERROR 05-08 12:32:05 [core.py:396]     get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "ERROR 05-08 12:32:05 [core.py:396]     check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "ERROR 05-08 12:32:05 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "ERROR 05-08 12:32:05 [core.py:396]     raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ERROR 05-08 12:32:05 [core.py:396] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 400, in run_engine_core\n",
      "    raise e\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "    self._initialize_kv_caches(vllm_config)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "    kv_cache_configs = [\n",
      "                       ^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "    get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "    check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "    raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n",
      "[rank0]:[W508 12:32:06.658769701 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed: gemma-2-9b-it | vllm | qa -- Engine core initialization failed. See root cause above.\n",
      "Running benchmark for gemma-2-9b-it with vllm on sql\n",
      "INFO 05-08 12:32:08 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 12:32:09 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:32:16 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:32:16.642934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746707536.660738  316840 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746707536.666092  316840 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746707536.680970  316840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707536.680991  316840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707536.680993  316840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707536.680995  316840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:32:16.684754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:32:25 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-9b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:32:25 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7ebc337d3a90>\n",
      "INFO 05-08 12:32:26 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:32:26 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:32:26 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:32:26 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-9b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.50it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.07it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.00it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:32:31 [loader.py:458] Loading weights took 4.77 seconds\n",
      "INFO 05-08 12:32:32 [gpu_model_runner.py:1347] Model loading took 17.2181 GiB and 5.053694 seconds\n",
      "INFO 05-08 12:32:46 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/2fc7af7ba1/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:32:46 [backends.py:430] Dynamo bytecode transform time: 13.86 s\n",
      "INFO 05-08 12:33:04 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 16.155 s\n",
      "INFO 05-08 12:33:13 [monitor.py:33] torch.compile takes 13.86 s in total\n",
      "ERROR 05-08 12:33:14 [core.py:396] EngineCore failed to start.\n",
      "ERROR 05-08 12:33:14 [core.py:396] Traceback (most recent call last):\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "ERROR 05-08 12:33:14 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 05-08 12:33:14 [core.py:396]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "ERROR 05-08 12:33:14 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "ERROR 05-08 12:33:14 [core.py:396]     self._initialize_kv_caches(vllm_config)\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "ERROR 05-08 12:33:14 [core.py:396]     kv_cache_configs = [\n",
      "ERROR 05-08 12:33:14 [core.py:396]                        ^\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "ERROR 05-08 12:33:14 [core.py:396]     get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "ERROR 05-08 12:33:14 [core.py:396]     check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "ERROR 05-08 12:33:14 [core.py:396]   File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "ERROR 05-08 12:33:14 [core.py:396]     raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ERROR 05-08 12:33:14 [core.py:396] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 400, in run_engine_core\n",
      "    raise e\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 71, in __init__\n",
      "    self._initialize_kv_caches(vllm_config)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 133, in _initialize_kv_caches\n",
      "    kv_cache_configs = [\n",
      "                       ^\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 134, in <listcomp>\n",
      "    get_kv_cache_config(vllm_config, kv_cache_spec_one_worker,\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 699, in get_kv_cache_config\n",
      "    check_enough_kv_cache_memory(vllm_config, kv_cache_spec, available_memory)\n",
      "  File \"/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/vllm/v1/core/kv_cache_utils.py\", line 527, in check_enough_kv_cache_memory\n",
      "    raise ValueError(\"No available memory for the cache blocks. \"\n",
      "ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.\n",
      "[rank0]:[W508 12:33:15.826390500 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed: gemma-2-9b-it | vllm | sql -- Engine core initialization failed. See root cause above.\n",
      "Running benchmark for gemma-2-2b-it-4bit with vllm on summarization\n",
      "INFO 05-08 12:33:18 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:33:18 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-08 12:33:18 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:33:26 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:33:26.635596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746707606.652501  317234 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746707606.657878  317234 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746707606.671685  317234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707606.671703  317234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707606.671706  317234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746707606.671707  317234 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:33:26.675842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:33:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:33:34 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x74a3681f4fd0>\n",
      "INFO 05-08 12:33:35 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:33:35 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:33:35 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:33:35 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit...\n",
      "INFO 05-08 12:33:35 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.19s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.20s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.13it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:33:47 [gpu_model_runner.py:1347] Model loading took 2.0924 GiB and 11.640020 seconds\n",
      "INFO 05-08 12:33:57 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/f3532c3769/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:33:57 [backends.py:430] Dynamo bytecode transform time: 10.05 s\n",
      "INFO 05-08 12:34:02 [backends.py:136] Cache the graph of shape None for later use\n",
      "INFO 05-08 12:34:37 [backends.py:148] Compiling a graph for general shape takes 39.29 s\n",
      "INFO 05-08 12:34:49 [monitor.py:33] torch.compile takes 49.34 s in total\n",
      "INFO 05-08 12:34:50 [kv_cache_utils.py:634] GPU KV cache size: 152,000 tokens\n",
      "INFO 05-08 12:34:50 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 37.11x\n",
      "INFO 05-08 12:35:57 [gpu_model_runner.py:1686] Graph capturing finished in 67 secs, took 0.93 GiB\n",
      "INFO 05-08 12:35:58 [core.py:159] init engine (profile, create kv cache, warmup model) took 130.64 seconds\n",
      "INFO 05-08 12:35:58 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:35:58] INFO config.py:54: PyTorch version 2.6.0 available.\n",
      "[2025-05-08 12:35:58] INFO config.py:112: TensorFlow version 2.19.0 available.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c06ba9a06d43df8e70c8524f87718c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ef7e93e567446fb4305ac155df9724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:36:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:36:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:11] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abfc60249e04556ad67ba0b240e13b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd566357eadb4e1d854fb5d06d1be6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:37:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:37:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:18] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaff3d9a7e14e18a97603d45b9d137b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811df31518b04494be3639ceda420ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:38:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:38:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:24] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a125dccb744a9e836e32b713eeeaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43729ce93ef40b9838630c6ec97942f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:39:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:39:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:32] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3cc1763c7b40748487774a3e8f3649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce6150b5ae34106bc1b28ff9e9e925b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:40:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:40:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:41:34] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-4bit on vllm/summarization:\n",
      "prompt_length                       5387.808000 ± 1970.082684\n",
      "TTFT                                      0.046260 ± 0.007733\n",
      "ATL                                       0.479724 ± 0.114536\n",
      "GL                                       24.399900 ± 0.487859\n",
      "TPS                                       2.200920 ± 0.512464\n",
      "SPS                                       0.148640 ± 0.034066\n",
      "Avg GPU Mem (MB)                      21867.872000 ± 0.016016\n",
      "Peak GPU Mem (MB)                     21867.880000 ± 0.000000\n",
      "Avg GPU Util (%)                         96.132000 ± 0.456149\n",
      "Total Energy (Wh)                         0.477958 ± 0.009746\n",
      "Avg Power (W)                            70.518000 ± 0.320471\n",
      "Energy per Token (J/token)               33.830877 ± 8.087313\n",
      "Energy per Sentence (J/sentence)       492.068811 ± 92.807912\n",
      "Memory Usage (MB)                     21867.880000 ± 0.000000\n",
      "Model Size (MB)                        2142.506347 ± 0.000000\n",
      "Overhead (MB)                         19725.373653 ± 0.000000\n",
      "ROUGE-1                                   0.383207 ± 0.095762\n",
      "ROUGE-2                                   0.131925 ± 0.079189\n",
      "ROUGE-L                                   0.242804 ± 0.078039\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:41:37.036803632 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-4bit | vllm | summarization\n",
      "Running benchmark for gemma-2-2b-it-4bit with vllm on qa\n",
      "INFO 05-08 12:41:39 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:41:39 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-08 12:41:39 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:41:47 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:41:48.487833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746708108.522225  321211 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746708108.532589  321211 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746708108.560113  321211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708108.560156  321211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708108.560161  321211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708108.560164  321211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:41:48.568290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:41:56 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:41:56 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x73209df8f490>\n",
      "INFO 05-08 12:41:57 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:41:57 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:41:57 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:41:57 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit...\n",
      "INFO 05-08 12:41:57 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.15s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.15s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:42:00 [gpu_model_runner.py:1347] Model loading took 2.0924 GiB and 2.441224 seconds\n",
      "INFO 05-08 12:42:09 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/f3532c3769/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:42:09 [backends.py:430] Dynamo bytecode transform time: 8.83 s\n",
      "INFO 05-08 12:42:19 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 8.988 s\n",
      "INFO 05-08 12:42:21 [monitor.py:33] torch.compile takes 8.83 s in total\n",
      "INFO 05-08 12:42:23 [kv_cache_utils.py:634] GPU KV cache size: 152,016 tokens\n",
      "INFO 05-08 12:42:23 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 37.11x\n",
      "INFO 05-08 12:43:27 [gpu_model_runner.py:1686] Graph capturing finished in 65 secs, took 0.93 GiB\n",
      "INFO 05-08 12:43:27 [core.py:159] init engine (profile, create kv cache, warmup model) took 87.39 seconds\n",
      "INFO 05-08 12:43:27 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056affe334c9479daada830fdcdd04f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4736e1849847d8bdf0116acc6dce5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305ec53ec4134c08be7c3dcd3124fafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1117c4d6fa764ca99278a6de67eab015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f267e87c5444c98dbaa87ea3ab792e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabd31f2b6584f6b82dd2f6cd98b595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d843c1aa122c4cc3b4884dde6be35083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec46128051274674b2121ae4bae8e35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdf1346e08e40f0ad76714f6dc84e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab375bdae3d49598d46037d8f8dbe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-4bit on vllm/qa:\n",
      "prompt_length                       1376.792000 ± 308.648558\n",
      "TTFT                                     0.036860 ± 0.000945\n",
      "ATL                                      1.693103 ± 0.798124\n",
      "GL                                       2.513460 ± 0.073220\n",
      "TPS                                      0.852360 ± 0.739900\n",
      "SPS                                      0.441320 ± 0.126470\n",
      "Avg GPU Mem (MB)                     21867.846000 ± 0.068068\n",
      "Peak GPU Mem (MB)                    21867.880000 ± 0.000000\n",
      "Avg GPU Util (%)                        91.086000 ± 2.835635\n",
      "Total Energy (Wh)                        0.048883 ± 0.002281\n",
      "Avg Power (W)                           70.124000 ± 4.573386\n",
      "Energy per Token (J/token)            118.686561 ± 56.508555\n",
      "Energy per Sentence (J/sentence)      166.308902 ± 28.292821\n",
      "Memory Usage (MB)                    21867.880000 ± 0.000000\n",
      "Model Size (MB)                       2142.506347 ± 0.000000\n",
      "Overhead (MB)                        19725.373653 ± 0.000000\n",
      "exact_match                              0.704000 ± 0.456948\n",
      "F1_score                                 0.818541 ± 0.325522\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:43:49.083981769 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-4bit | vllm | qa\n",
      "Running benchmark for gemma-2-2b-it-4bit with vllm on sql\n",
      "INFO 05-08 12:43:51 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:43:51 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-08 12:43:51 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:43:58 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:43:59.330101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746708239.348581  321897 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746708239.354228  321897 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746708239.369236  321897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708239.369258  321897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708239.369260  321897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708239.369262  321897 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:43:59.373629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:44:07 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:44:08 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7104bc1b9490>\n",
      "INFO 05-08 12:44:09 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:44:09 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:44:09 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:44:09 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-4bit...\n",
      "INFO 05-08 12:44:09 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.19s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.19s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.49it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.49it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:44:12 [gpu_model_runner.py:1347] Model loading took 2.0924 GiB and 2.264602 seconds\n",
      "INFO 05-08 12:44:21 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/f3532c3769/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:44:21 [backends.py:430] Dynamo bytecode transform time: 9.21 s\n",
      "INFO 05-08 12:44:31 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 8.322 s\n",
      "INFO 05-08 12:44:33 [monitor.py:33] torch.compile takes 9.21 s in total\n",
      "INFO 05-08 12:44:34 [kv_cache_utils.py:634] GPU KV cache size: 152,016 tokens\n",
      "INFO 05-08 12:44:34 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 37.11x\n",
      "INFO 05-08 12:45:44 [gpu_model_runner.py:1686] Graph capturing finished in 69 secs, took 0.93 GiB\n",
      "INFO 05-08 12:45:44 [core.py:159] init engine (profile, create kv cache, warmup model) took 92.31 seconds\n",
      "INFO 05-08 12:45:44 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b05505dbe5f487ab3e7fca4c68889b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a08b8409fb340e797d4ef00b8c66781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbe7dfb0cba40488a2bdc514472f218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1646988265498498f1b94c6eddeebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9c9107526d4156b1d46cbbfa4c8d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df5a521003d4fc89db5c517119a8cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acba01243883481e92eae879c54ffda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57f9db8ba564d28831b779da4d5599c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40351ff6a48b432d8c00e2a03156f1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa126be564b4afa80fa8c095b9ab362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-4bit on vllm/sql:\n",
      "prompt_length                       1201.928000 ± 296.321737\n",
      "TTFT                                     0.038380 ± 0.001290\n",
      "ATL                                      2.060765 ± 2.014728\n",
      "GL                                       4.573920 ± 0.105246\n",
      "TPS                                      1.798700 ± 1.714994\n",
      "SPS                                      0.344340 ± 0.373507\n",
      "Avg GPU Mem (MB)                     21867.862000 ± 0.036036\n",
      "Peak GPU Mem (MB)                    21867.880000 ± 0.000000\n",
      "Avg GPU Util (%)                        91.358000 ± 1.006341\n",
      "Total Energy (Wh)                        0.087142 ± 0.004307\n",
      "Avg Power (W)                           68.558000 ± 2.346134\n",
      "Energy per Token (J/token)           141.697192 ± 138.951781\n",
      "Energy per Sentence (J/sentence)      283.907700 ± 83.661755\n",
      "Memory Usage (MB)                    21867.880000 ± 0.000000\n",
      "Model Size (MB)                       2142.506347 ± 0.000000\n",
      "Overhead (MB)                        19725.373653 ± 0.000000\n",
      "AST_equal                                0.102000 ± 0.302951\n",
      "Normalized_equal                         0.144000 ± 0.351441\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:46:30.351251013 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-4bit | vllm | sql\n",
      "Running benchmark for gemma-2-2b-it-8bit with vllm on summarization\n",
      "INFO 05-08 12:46:33 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:46:33 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "WARNING 05-08 12:46:33 [config.py:866] CUDA graph is not supported on BitsAndBytes 8bit yet, fallback to the eager mode.\n",
      "INFO 05-08 12:46:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 05-08 12:46:33 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 05-08 12:46:41 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:46:41.999657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746708402.017079  322480 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746708402.022476  322480 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746708402.037729  322480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708402.037748  322480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708402.037750  322480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708402.037752  322480 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:46:42.041876: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:46:49 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}\n",
      "WARNING 05-08 12:46:49 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x725e53634890>\n",
      "INFO 05-08 12:46:50 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:46:50 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:46:50 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:46:50 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit...\n",
      "INFO 05-08 12:46:50 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:12<00:00, 12.04s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:12<00:00, 12.04s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.38s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.38s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:47:05 [gpu_model_runner.py:1347] Model loading took 2.9919 GiB and 13.644778 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:47:11 [kv_cache_utils.py:634] GPU KV cache size: 140,800 tokens\n",
      "INFO 05-08 12:47:11 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 34.38x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:47:12 [core.py:159] init engine (profile, create kv cache, warmup model) took 7.14 seconds\n",
      "INFO 05-08 12:47:12 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb10210dec946a7be0b5d071ac83c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bbd4f06ad6489fb2b8830acd14a40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:47:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:47:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:48:33] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0228d5478ca4272be609ee4315d40cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd583a5c6dc4854af0fae08bde0dfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:49:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:49:50] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5368e0c4a1d412aa6f27fba1447ebb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83162b41f65040e68df1584767c793f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:50:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:50:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:02] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9bbf4ff8a94052ab5f8e78c22396ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60845f9bb3a14b9690135f48e69f839b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:51:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:51:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:52:31] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86432603807f4c5ea35d1ce5a5370923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529a418c4f34447b80bb7e620d620425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:53:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:20] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:21] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:22] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:23] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:24] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:25] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:26] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:53:46] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-8bit on vllm/summarization:\n",
      "prompt_length                       5387.808000 ± 1970.082684\n",
      "TTFT                                      0.129700 ± 0.009844\n",
      "ATL                                       0.643005 ± 0.152975\n",
      "GL                                       32.736080 ± 2.619687\n",
      "TPS                                       1.642460 ± 0.385952\n",
      "SPS                                       0.109700 ± 0.023968\n",
      "Avg GPU Mem (MB)                      20959.712000 ± 1.464331\n",
      "Peak GPU Mem (MB)                     20960.280000 ± 0.800801\n",
      "Avg GPU Util (%)                         65.496000 ± 2.688181\n",
      "Total Energy (Wh)                         0.576690 ± 0.036152\n",
      "Avg Power (W)                            63.506000 ± 1.100202\n",
      "Energy per Token (J/token)               40.779247 ± 9.462316\n",
      "Energy per Sentence (J/sentence)      602.774568 ± 109.044056\n",
      "Memory Usage (MB)                     20960.280000 ± 0.800801\n",
      "Model Size (MB)                        3095.584147 ± 0.000000\n",
      "Overhead (MB)                         17864.695853 ± 0.800801\n",
      "ROUGE-1                                   0.365161 ± 0.096975\n",
      "ROUGE-2                                   0.120515 ± 0.075898\n",
      "ROUGE-L                                   0.232226 ± 0.075994\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:53:47.716943112 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-8bit | vllm | summarization\n",
      "Running benchmark for gemma-2-2b-it-8bit with vllm on qa\n",
      "INFO 05-08 12:53:49 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:53:49 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "WARNING 05-08 12:53:49 [config.py:866] CUDA graph is not supported on BitsAndBytes 8bit yet, fallback to the eager mode.\n",
      "INFO 05-08 12:53:49 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 05-08 12:53:49 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 05-08 12:53:58 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:53:59.628053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746708839.656912  325394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746708839.665367  325394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746708839.688191  325394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708839.688222  325394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708839.688226  325394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708839.688228  325394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:53:59.694942: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:54:09 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}\n",
      "WARNING 05-08 12:54:09 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x72ab2d039050>\n",
      "INFO 05-08 12:54:10 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:54:10 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:54:10 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:54:10 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit...\n",
      "INFO 05-08 12:54:10 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:05<00:00,  5.21s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:05<00:00,  5.21s/it]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.11s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.11s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:54:17 [gpu_model_runner.py:1347] Model loading took 2.9919 GiB and 6.640209 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:54:25 [kv_cache_utils.py:634] GPU KV cache size: 140,800 tokens\n",
      "INFO 05-08 12:54:25 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 34.38x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:54:25 [core.py:159] init engine (profile, create kv cache, warmup model) took 8.04 seconds\n",
      "INFO 05-08 12:54:25 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a19d74c739423283af4052e7ef2374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beca6de0e074e94832cf92963ed33f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7909b17103c54bb999dd2fe6760bf350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff99fc89c8fc4f9cbdca7ce3c0a824db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d655fb2678446ce85265cd9acc66e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84982ae5fe0341d0ae4cbbfa99ae7157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac3826e0ce448889007d33b33f1e43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66216d3b564a4afe8bdc787ef795af53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700719212a1b48a4af81140fb201b2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf387b2904d741cea0017b79bfc71060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-8bit on vllm/qa:\n",
      "prompt_length                       1376.792000 ± 308.648558\n",
      "TTFT                                     0.173760 ± 0.049968\n",
      "ATL                                      3.619176 ± 1.972717\n",
      "GL                                       5.885000 ± 0.827900\n",
      "TPS                                      0.411840 ± 0.336980\n",
      "SPS                                      0.197460 ± 0.063931\n",
      "Avg GPU Mem (MB)                     20956.074000 ± 3.253262\n",
      "Peak GPU Mem (MB)                    20957.480000 ± 0.800801\n",
      "Avg GPU Util (%)                        58.454000 ± 7.220242\n",
      "Total Energy (Wh)                        0.093448 ± 0.009264\n",
      "Avg Power (W)                           57.528000 ± 2.739128\n",
      "Energy per Token (J/token)           206.904646 ± 110.092570\n",
      "Energy per Sentence (J/sentence)      312.511134 ± 64.669985\n",
      "Memory Usage (MB)                    20957.480000 ± 0.800801\n",
      "Model Size (MB)                       3095.584147 ± 0.000000\n",
      "Overhead (MB)                        17861.895853 ± 0.800801\n",
      "exact_match                              0.734000 ± 0.442307\n",
      "F1_score                                 0.847761 ± 0.299234\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:55:03.509464795 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-8bit | vllm | qa\n",
      "Running benchmark for gemma-2-2b-it-8bit with vllm on sql\n",
      "INFO 05-08 12:55:06 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 05-08 12:55:06 [config.py:830] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "WARNING 05-08 12:55:06 [config.py:866] CUDA graph is not supported on BitsAndBytes 8bit yet, fallback to the eager mode.\n",
      "INFO 05-08 12:55:06 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 05-08 12:55:06 [cuda.py:93] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 05-08 12:55:14 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:55:14.453143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746708914.469974  325823 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746708914.474869  325823 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746708914.488033  325823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708914.488057  325823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708914.488060  325823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746708914.488061  325823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:55:14.491958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:55:21 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}\n",
      "WARNING 05-08 12:55:21 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7eabd36ac190>\n",
      "INFO 05-08 12:55:21 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:55:21 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:55:21 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:55:21 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it-8bit...\n",
      "INFO 05-08 12:55:22 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.29it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.29it/s]\n",
      "\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.21it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.21it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:55:24 [gpu_model_runner.py:1347] Model loading took 2.9919 GiB and 1.808613 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:55:27 [kv_cache_utils.py:634] GPU KV cache size: 140,800 tokens\n",
      "INFO 05-08 12:55:27 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 34.38x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/ubuntu/fastllm_venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:55:28 [core.py:159] init engine (profile, create kv cache, warmup model) took 3.97 seconds\n",
      "INFO 05-08 12:55:28 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ee2598615e4bbbaab5ece2867d466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0482ddfd3850423aa5b8124c96b4abb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1619518ee4084b1b9deeff9f6bbbfa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3f35dad3614449907e75f42d6eec23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754e4db12bc44fea9bb3932a48bc94c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a4337aacd3470a90eef9938fad685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b14026c88a474fa3dafc7d0b1ba1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a44c3bb7e64a95bf3302d98e3c240b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5c9842fc1948f2ac437cc617fd471b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c1213bc9e44b7b81509a8a7ab15bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it-8bit on vllm/sql:\n",
      "prompt_length                       1201.928000 ± 296.321737\n",
      "TTFT                                     0.141740 ± 0.037875\n",
      "ATL                                      8.498370 ± 4.702592\n",
      "GL                                      11.446480 ± 0.915724\n",
      "TPS                                      0.384640 ± 0.589597\n",
      "SPS                                      0.113500 ± 0.104040\n",
      "Avg GPU Mem (MB)                     20950.320000 ± 3.204806\n",
      "Peak GPU Mem (MB)                    20951.080000 ± 2.402404\n",
      "Avg GPU Util (%)                        40.572000 ± 2.920142\n",
      "Total Energy (Wh)                        0.164631 ± 0.010456\n",
      "Avg Power (W)                           51.858000 ± 1.412546\n",
      "Energy per Token (J/token)           440.318250 ± 242.700063\n",
      "Energy per Sentence (J/sentence)     566.097747 ± 116.412233\n",
      "Memory Usage (MB)                    20951.080000 ± 2.402404\n",
      "Model Size (MB)                       3095.584147 ± 0.000000\n",
      "Overhead (MB)                        17855.495853 ± 2.402404\n",
      "AST_equal                                0.068000 ± 0.251998\n",
      "Normalized_equal                         0.092000 ± 0.289315\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 12:56:43.094629546 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it-8bit | vllm | sql\n",
      "Running benchmark for gemma-2-2b-it with vllm on summarization\n",
      "INFO 05-08 12:56:45 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 12:56:45 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 12:56:52 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:56:52.586240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746709012.604017  326065 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746709012.609353  326065 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746709012.623829  326065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709012.623852  326065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709012.623855  326065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709012.623858  326065 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:56:52.628222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:56:58 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 12:56:59 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7de8f5758e90>\n",
      "INFO 05-08 12:56:59 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 12:56:59 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 12:56:59 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 12:56:59 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:03<00:00,  3.90s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:03<00:00,  3.90s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:57:04 [loader.py:458] Loading weights took 4.26 seconds\n",
      "INFO 05-08 12:57:04 [gpu_model_runner.py:1347] Model loading took 4.9000 GiB and 4.493391 seconds\n",
      "INFO 05-08 12:57:13 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/e1e0067345/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 12:57:13 [backends.py:430] Dynamo bytecode transform time: 8.48 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:W0508 12:57:15.145000 326065 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 12:57:18 [backends.py:136] Cache the graph of shape None for later use\n",
      "INFO 05-08 12:57:56 [backends.py:148] Compiling a graph for general shape takes 42.97 s\n",
      "INFO 05-08 12:58:09 [monitor.py:33] torch.compile takes 51.45 s in total\n",
      "INFO 05-08 12:58:10 [kv_cache_utils.py:634] GPU KV cache size: 123,696 tokens\n",
      "INFO 05-08 12:58:10 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 30.20x\n",
      "INFO 05-08 12:59:15 [gpu_model_runner.py:1686] Graph capturing finished in 65 secs, took 0.42 GiB\n",
      "INFO 05-08 12:59:15 [core.py:159] init engine (profile, create kv cache, warmup model) took 131.09 seconds\n",
      "INFO 05-08 12:59:15 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b77399cd4624f109425ecf4a99b58a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d87665a5b54c0483a8e08f5fc86047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 12:59:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 12:59:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:19] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20d0cb9e3974617ae1c5edc6e21ee29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30623ed6f1a94a08b2927b613cd9eab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 13:00:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:00:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:17] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:18] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:19] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb4bac432d645b59e3c9fc183e3a567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f82a59aea1415a92b4e7315cede3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 13:01:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:01:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:13] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:14] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:15] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:16] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:16] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39f227ccc8a45719c0852d1d03042c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefc3aa346d84fb7827b3bad7e1c81a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 13:02:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:02:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:10] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:11] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:12] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:12] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546d37c8ce744375b291049d951f592b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c6267ab54f441eb773347f07500b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 13:03:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:27] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:28] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:29] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:30] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:31] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:32] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:33] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:34] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:35] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:36] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:37] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:38] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:39] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:40] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:41] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:42] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:43] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:44] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:45] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:46] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:47] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:48] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:49] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:50] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:51] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:52] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:53] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:54] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:55] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:56] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:57] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:58] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:03:59] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:00] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:01] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:02] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:03] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:04] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:05] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:06] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:07] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:08] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:09] INFO rouge_scorer.py:83: Using default tokenizer.\n",
      "[2025-05-08 13:04:09] INFO rouge_scorer.py:83: Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it on vllm/summarization:\n",
      "prompt_length                       5387.808000 ± 1970.082684\n",
      "TTFT                                      0.030980 ± 0.002383\n",
      "ATL                                       0.291103 ± 0.063541\n",
      "GL                                       15.079260 ± 0.349494\n",
      "TPS                                       3.594480 ± 0.763731\n",
      "SPS                                       0.239760 ± 0.048813\n",
      "Avg GPU Mem (MB)                      21353.874000 ± 0.012012\n",
      "Peak GPU Mem (MB)                     21353.880000 ± 0.000000\n",
      "Avg GPU Util (%)                         95.490000 ± 0.763863\n",
      "Total Energy (Wh)                         0.292071 ± 0.006792\n",
      "Avg Power (W)                            69.728000 ± 0.427201\n",
      "Energy per Token (J/token)               20.298625 ± 4.433529\n",
      "Energy per Sentence (J/sentence)       302.049092 ± 53.214486\n",
      "Memory Usage (MB)                     21353.880000 ± 0.000000\n",
      "Model Size (MB)                        5007.298138 ± 0.000000\n",
      "Overhead (MB)                         16346.581862 ± 0.000000\n",
      "ROUGE-1                                   0.369732 ± 0.097330\n",
      "ROUGE-2                                   0.123078 ± 0.075746\n",
      "ROUGE-L                                   0.233331 ± 0.074224\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 13:04:12.788618549 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it | vllm | summarization\n",
      "Running benchmark for gemma-2-2b-it with vllm on qa\n",
      "INFO 05-08 13:04:15 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 13:04:15 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 13:04:23 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:04:23.418830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746709463.436731  328971 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746709463.441593  328971 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746709463.454609  328971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709463.454640  328971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709463.454643  328971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709463.454645  328971 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 13:04:23.458449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 13:04:29 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 13:04:30 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fbeb7cf0b10>\n",
      "INFO 05-08 13:04:30 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 13:04:30 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 13:04:30 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 13:04:30 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.51s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.51s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 13:04:32 [loader.py:458] Loading weights took 1.96 seconds\n",
      "INFO 05-08 13:04:33 [gpu_model_runner.py:1347] Model loading took 4.9000 GiB and 2.176391 seconds\n",
      "INFO 05-08 13:04:42 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/e1e0067345/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 13:04:42 [backends.py:430] Dynamo bytecode transform time: 9.14 s\n",
      "INFO 05-08 13:04:52 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 9.368 s\n",
      "INFO 05-08 13:04:54 [monitor.py:33] torch.compile takes 9.14 s in total\n",
      "INFO 05-08 13:04:55 [kv_cache_utils.py:634] GPU KV cache size: 123,728 tokens\n",
      "INFO 05-08 13:04:55 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 30.21x\n",
      "INFO 05-08 13:05:49 [gpu_model_runner.py:1686] Graph capturing finished in 53 secs, took 0.42 GiB\n",
      "INFO 05-08 13:05:49 [core.py:159] init engine (profile, create kv cache, warmup model) took 75.56 seconds\n",
      "INFO 05-08 13:05:49 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18bf4b0e0c84aa6a9cf9a209b5b7e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a22c2d1d6cf40e293551bd1b6b7529e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded60ba274724dcdab39fc6baeccd349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4f3dccb77142fbb8597c4115fc10aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1534d59186184c3895472507e3cb5202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1cd9a1ff3545e58d3fc8741ed48aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3522fc4b8b4a8b8c738976146a63f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dbe019ac1b44a2b78c46f166554351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebde1b8a31c4fb3b37572deeb98d92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f822b49f90c44e9baa44607a1ee99761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it on vllm/qa:\n",
      "prompt_length                       1376.792000 ± 308.648558\n",
      "TTFT                                     0.027920 ± 0.000248\n",
      "ATL                                      1.301897 ± 0.679328\n",
      "GL                                       2.100820 ± 0.104391\n",
      "TPS                                      1.137100 ± 0.932444\n",
      "SPS                                      0.542640 ± 0.169862\n",
      "Avg GPU Mem (MB)                     21353.462000 ± 0.836837\n",
      "Peak GPU Mem (MB)                    21353.480000 ± 0.800801\n",
      "Avg GPU Util (%)                        90.496000 ± 5.728275\n",
      "Total Energy (Wh)                        0.039425 ± 0.003045\n",
      "Avg Power (W)                           67.696000 ± 5.640253\n",
      "Energy per Token (J/token)             87.996944 ± 46.487840\n",
      "Energy per Sentence (J/sentence)      131.931049 ± 26.249155\n",
      "Memory Usage (MB)                    21353.880000 ± 0.000000\n",
      "Model Size (MB)                       5007.298138 ± 0.000000\n",
      "Overhead (MB)                        16346.581862 ± 0.000000\n",
      "exact_match                              0.738000 ± 0.440163\n",
      "F1_score                                 0.847074 ± 0.300998\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 13:06:05.337855013 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it | vllm | qa\n",
      "Running benchmark for gemma-2-2b-it with vllm on sql\n",
      "INFO 05-08 13:06:07 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 05-08 13:06:07 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 05-08 13:06:14 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:06:15.419432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746709575.439335  329296 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746709575.445558  329296 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746709575.463465  329296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709575.463500  329296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709575.463502  329296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746709575.463504  329296 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 13:06:15.468791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 13:06:22 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', speculative_config=None, tokenizer='/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/ubuntu/fast_llm_inference/models/gemma-2-2b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-08 13:06:22 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x726b4519d610>\n",
      "INFO 05-08 13:06:23 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-08 13:06:23 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-08 13:06:23 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-08 13:06:23 [gpu_model_runner.py:1329] Starting to load model /home/ubuntu/fast_llm_inference/models/gemma-2-2b-it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.01it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.01it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-08 13:06:25 [loader.py:458] Loading weights took 1.25 seconds\n",
      "INFO 05-08 13:06:26 [gpu_model_runner.py:1347] Model loading took 4.9000 GiB and 1.474595 seconds\n",
      "INFO 05-08 13:06:34 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/e1e0067345/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-08 13:06:34 [backends.py:430] Dynamo bytecode transform time: 8.55 s\n",
      "INFO 05-08 13:06:42 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 7.618 s\n",
      "INFO 05-08 13:06:44 [monitor.py:33] torch.compile takes 8.55 s in total\n",
      "INFO 05-08 13:06:45 [kv_cache_utils.py:634] GPU KV cache size: 123,728 tokens\n",
      "INFO 05-08 13:06:45 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 30.21x\n",
      "INFO 05-08 13:07:37 [gpu_model_runner.py:1686] Graph capturing finished in 51 secs, took 0.42 GiB\n",
      "INFO 05-08 13:07:37 [core.py:159] init engine (profile, create kv cache, warmup model) took 71.09 seconds\n",
      "INFO 05-08 13:07:37 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77d24c11d074b9581542ed0a507e7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61ee84180774325affc5eefe503b6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d450389aeaf04652b77a6ef935414073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08db26e468dd42eab52340e2d53bd8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e27c3e3aebe4ffd8946d3d4522a5cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07227890ef7241daaffc00bc0ed5a7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bb903df5f64e68a57090c531efec9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbac7c5eb3e34b0fa9824fc34e541d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72ff35a9dd94411b9e81e3dac24a6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dd6172dfd34fc5bade5f9a975ba4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for gemma-2-2b-it on vllm/sql:\n",
      "prompt_length                       1201.928000 ± 296.321737\n",
      "TTFT                                     0.028900 ± 0.001115\n",
      "ATL                                      2.362990 ± 1.508970\n",
      "GL                                       3.492680 ± 0.092415\n",
      "TPS                                      1.477440 ± 1.994556\n",
      "SPS                                      0.367280 ± 0.348185\n",
      "Avg GPU Mem (MB)                     21353.856000 ± 0.048048\n",
      "Peak GPU Mem (MB)                    21353.880000 ± 0.000000\n",
      "Avg GPU Util (%)                        89.626000 ± 1.444131\n",
      "Total Energy (Wh)                        0.066461 ± 0.004528\n",
      "Avg Power (W)                           68.442000 ± 3.315642\n",
      "Energy per Token (J/token)           161.894119 ± 104.133036\n",
      "Energy per Sentence (J/sentence)      228.280406 ± 47.481958\n",
      "Memory Usage (MB)                    21353.880000 ± 0.000000\n",
      "Model Size (MB)                       5007.298138 ± 0.000000\n",
      "Overhead (MB)                        16346.581862 ± 0.000000\n",
      "AST_equal                                0.086000 ± 0.280645\n",
      "Normalized_equal                         0.114000 ± 0.318130\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W508 13:08:13.961451892 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed: gemma-2-2b-it | vllm | sql\n"
     ]
    }
   ],
   "source": [
    "from benchmark.benchmark import ModelBenchmark\n",
    "import torch\n",
    "\n",
    "\n",
    "def run_benchmark(backend, model_name, task, base_path=\"/home/ubuntu/fast_llm_inference/models\", samples=500, verbose=False, batch_size=100):\n",
    "    print(f\"Running benchmark for {model_name} with {backend} on {task}\")\n",
    "    try:\n",
    "        bm = ModelBenchmark(\n",
    "            backend=backend,\n",
    "            model_name=model_name,\n",
    "            model_path=f\"{base_path}/{model_name}\",\n",
    "            task=task,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        bm.run(samples=samples, batch_size=batch_size)\n",
    "        bm.close()\n",
    "        del bm\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"✅ Completed: {model_name} | {backend} | {task}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed: {model_name} | {backend} | {task} -- {e}\")\n",
    "        torch.cuda.empty_cache()  # ensure no memory leak on error\n",
    "\n",
    "\n",
    "base_path = \"/home/ubuntu/fast_llm_inference/models\"\n",
    "\n",
    "backends = [\"vllm\"] #, \"huggingface\",\"deepspeed_mii\", \"llama.cpp\"]\n",
    "models   = [\n",
    "   # \"llama-3.1-8B-Instruct\",\n",
    "   # \"llama-3.1-8B-Instruct-4bit\",\n",
    "   # \"llama-3.1-8B-Instruct-8bit\",\n",
    "    \"llama-3.2-3b-instruct\",\n",
    "    \"llama-3.2-1b-instruct\",\n",
    "    \"llama-3.2-3b-instruct-4bit\",\n",
    "    \"llama-3.2-1b-instruct-4bit\",\n",
    "    \"llama-3.2-3b-instruct-8bit\",\n",
    "    \"llama-3.2-1b-instruct-8bit\",\n",
    "   \n",
    "   # \"Qwen2.5-7B-Instruct\",\n",
    "   # \"Qwen2.5-7B-Instruct-4bit\",\n",
    "   ### \"Qwen2.5-7B-Instruct-8bit\", # some weird error\n",
    "    \"Qwen2.5-3B-Instruct\",\n",
    "    \"Qwen2.5-1.5B-Instruct\",\n",
    "    \"Qwen2.5-0.5B-Instruct\",\n",
    "    \"Qwen2.5-3B-Instruct-4bit\",\n",
    "    \"Qwen2.5-1.5B-Instruct-4bit\",\n",
    "    \"Qwen2.5-0.5B-Instruct-4bit\",\n",
    "    \"Qwen2.5-3B-Instruct-8bit\",\n",
    "    \"Qwen2.5-1.5B-Instruct-8bit\",\n",
    "    \"Qwen2.5-0.5B-Instruct-8bit\",\n",
    "\n",
    "\n",
    "    #\"gemma-2-9b-it-bnb4\",\n",
    "    #\"gemma-2-9b-it-8bit\",\n",
    "    ### \"gemma-2-9b-it\", # too large\n",
    "    #\"gemma-2-2b-it-4bit\",\n",
    "    #\"gemma-2-2b-it-8bit\",\n",
    "    #\"gemma-2-2b-it\",\n",
    "]\n",
    "tasks    = [\"summarization\", \"qa\", \"sql\",]\n",
    "\n",
    "for backend in backends:\n",
    "    for model in models:\n",
    "        for task in tasks:\n",
    "            run_benchmark(\n",
    "                backend=backend,\n",
    "                model_name=model,\n",
    "                task=task,\n",
    "                base_path=base_path,\n",
    "                samples=500,\n",
    "                verbose=False,\n",
    "                batch_size=100,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastllm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
