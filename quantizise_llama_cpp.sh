

/home/ubuntu/fast_llm_inference/llama.cpp/build/bin/llama-quantize \
/home/ubuntu/fast_llm_inference/llama-3.1-8B-Instruct-gguf/llama-3.1-8B-Instruct-f16.gguf \
/home/ubuntu/fast_llm_inference/llama-3.1-8B-Instruct-gguf/llama-3.1-8B-Instruct-Q8_0.gguf \
Q8_0
