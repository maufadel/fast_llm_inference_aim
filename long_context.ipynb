{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# List of QA benchmark subsets in LongBench\n",
    "qa_datasets = [\n",
    "    \"narrativeqa\",\n",
    "    \"qasper\",\n",
    "    \"multifieldqa_en\",\n",
    "    \"multifieldqa_zh\",\n",
    "    \"hotpotqa\",\n",
    "    \"2wikimqa\",\n",
    "    \"musique\",\n",
    "    \"dureader\",\n",
    "    \"triviaqa\",\n",
    "]\n",
    "\n",
    "qa_splits = {}\n",
    "for name in qa_datasets:\n",
    "    # Load only the 'test' split of each QA subset\n",
    "    qa_splits[name] = load_dataset(\"THUDM/LongBench\", name, split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: inspect the first example of each\n",
    "for name, ds in qa_splits.items():\n",
    "    print(f\"{name} â†’ {len(ds)} examples, first record keys: {list(ds[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_splits[\"narrativeqa\"][0]  # Example to show the structure of the first recor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea37740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 3) Define bucket ranges (token-length) for ~2k, 4k, 8k, 16k, 32k\n",
    "bucket_specs = [\n",
    "    (\"3k\",  0,      3072),\n",
    "    (\"4k\",  3072,   4096),\n",
    "    (\"8k\",  4097,   8192),\n",
    "    (\"16k\", 8193,   16384),\n",
    "    (\"32k\", 16385,  32768)\n",
    "]\n",
    "\n",
    "def assign_bucket(length: int) -> str:\n",
    "    for label, lo, hi in bucket_specs:\n",
    "        if lo <= length <= hi:\n",
    "            return label\n",
    "    return \"\"\n",
    "\n",
    "# 4) Collect up to 1000 English examples per bucket\n",
    "buckets = defaultdict(list)\n",
    "MAX_PER_BUCKET = 100\n",
    "\n",
    "for ds_name, ds in qa_splits.items():\n",
    "    for example in ds:\n",
    "        # Only keep English examples\n",
    "        if example.get(\"language\") != \"en\":\n",
    "            continue\n",
    "\n",
    "        length = example.get(\"length\", None)\n",
    "        if length is None:\n",
    "            continue\n",
    "        \n",
    "        bucket_label = assign_bucket(length)\n",
    "        if not bucket_label:\n",
    "            continue\n",
    "        \n",
    "        if len(buckets[bucket_label]) >= MAX_PER_BUCKET:\n",
    "            continue\n",
    "        \n",
    "        context  = example[\"context\"]\n",
    "        question = example[\"input\"]\n",
    "        raw_answers = example.get(\"answers\", [])\n",
    "        answer = raw_answers[0] if isinstance(raw_answers, list) and raw_answers else raw_answers\n",
    "        \n",
    "        buckets[bucket_label].append({\n",
    "            \"context\":  context,\n",
    "            \"question\": question,\n",
    "            \"answer\":   answer,\n",
    "            \"length\":   length,\n",
    "            \"dataset\":  ds_name\n",
    "        })\n",
    "        \n",
    "        # Stop if all buckets have 1000 examples\n",
    "        if all(len(buckets[label]) >= MAX_PER_BUCKET for label, _, _ in bucket_specs):\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "# 5) Verify counts\n",
    "for label, _, _ in bucket_specs:\n",
    "    print(f\"Bucket '{label}' has {len(buckets[label])} English examples (target: {MAX_PER_BUCKET})\")\n",
    "\n",
    "\n",
    "# 6) Write all buckets to a single CSV file with 'context_range' column\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"bucketed_qas_csv\", exist_ok=True)\n",
    "\n",
    "# Define CSV fieldnames (including new 'context_range' column)\n",
    "fieldnames = [\"context\", \"question\", \"answer\", \"length\", \"dataset\", \"context_range\"]\n",
    "\n",
    "# Collect all rows from each bucket into a single list\n",
    "all_rows = []\n",
    "for label, _, _ in bucket_specs:\n",
    "    for ex in buckets[label]:\n",
    "        all_rows.append({\n",
    "            \"context\":       ex[\"context\"],\n",
    "            \"question\":      ex[\"question\"],\n",
    "            \"answer\":        ex[\"answer\"],\n",
    "            \"length\":        ex[\"length\"],\n",
    "            \"dataset\":       ex[\"dataset\"],\n",
    "            \"context_range\": label\n",
    "        })\n",
    "\n",
    "# Write them all to one CSV\n",
    "out_path = \"bucketed_qas_csv/longbench_all_buckets_100.csv\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\", newline=\"\") as fout:\n",
    "    writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in all_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Done. Saved merged CSV with 'context_range' column to '{out_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/ubuntu/fast_llm_inference/long_context_data/longbench_all_buckets_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[499]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[499]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4321d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 1) Define local paths and HF repo\n",
    "LOCAL_CSV_PATH = \"/home/ubuntu/fast_llm_inference/long_context_data/longbench_all_buckets_100.csv\"\n",
    "HF_REPO_ID     = \"slinusc/qa_increasing_context_length\"\n",
    "\n",
    "# 2) Clone the existing dataset repo into a temporary folder\n",
    "LOCAL_REPO_DIR = \"./hf_qa_dataset_repo\"\n",
    "if os.path.isdir(LOCAL_REPO_DIR):\n",
    "    shutil.rmtree(LOCAL_REPO_DIR)\n",
    "\n",
    "repo = Repository(\n",
    "    local_dir=LOCAL_REPO_DIR,\n",
    "    clone_from=HF_REPO_ID,\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "# 3) Copy your CSV into the cloned repo directory\n",
    "dest_path = os.path.join(LOCAL_REPO_DIR, \"longbench_all_buckets_100.csv\")\n",
    "shutil.copyfile(LOCAL_CSV_PATH, dest_path)\n",
    "\n",
    "# 4) Create or update a minimal README.md (mentioning 'context_range' instead of 'bucket')\n",
    "readme_path = os.path.join(LOCAL_REPO_DIR, \"README.md\")\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\n",
    "        \"# QA Increasing Context Length\\n\\n\"\n",
    "        \"This dataset contains a single CSV (`longbench_all_buckets_100.csv`) with QA examples\\n\"\n",
    "        \"bucketed by context length (2k, 4k, 8k, 16k, 32k). Each row has:\\n\"\n",
    "        \"- `context`\\n\"\n",
    "        \"- `question`\\n\"\n",
    "        \"- `answer`\\n\"\n",
    "        \"- `length` (token count)\\n\"\n",
    "        \"- `dataset` (LongBench subset)\\n\"\n",
    "        \"- `context_range` (2k/4k/8k/16k/32k)\\n\"\n",
    "    )\n",
    "\n",
    "# 5) Add, commit, and push changes to the HF Hub\n",
    "repo.git_add(auto_lfs_track=True)\n",
    "repo.git_commit(\"Update README to use 'context_range' and add longbench_all_buckets_100.csv\")\n",
    "repo.git_push()\n",
    "\n",
    "print(\"Successfully pushed updated CSV and README to:\", HF_REPO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77584dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Replace \"your-username/longbench-qa-increasing-context\" \n",
    "# with the actual dataset ID on huggingface.co/datasets\n",
    "ds = load_dataset(\"slinusc/ContextStretchQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.tasks.qa import QATask\n",
    "\n",
    "# Create a QATask instance using the loaded dataset\n",
    "qa_task = QATask()\n",
    "\n",
    "qa_task.generate_prompts(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3816613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.tasks.long_context import LongContextQATask\n",
    "\n",
    "long_qa_task = LongContextQATask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, refs, crs  = long_qa_task.generate_prompts(num_samples_per_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83851cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6444c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.benchmark import ModelBenchmark\n",
    "\n",
    "bm = ModelBenchmark(\n",
    "    backend=\"mii\",\n",
    "    model_path=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    model_name=\"Mistral-7B-Instruct-v0.3\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc90e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_report, detailed_report = bm.run(task=\"sql\", scenario=\"server\", run_time=60, concurrent_users=10, requests_per_user_per_min=10)\n",
    "\n",
    "run_report, detailed_report = bm.run(task=\"long_context_qa\", scenario=\"long_context\", samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc133c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_size_mb</th>\n",
       "      <th>task</th>\n",
       "      <th>scenario</th>\n",
       "      <th>backend</th>\n",
       "      <th>startup</th>\n",
       "      <th>ttft_sec</th>\n",
       "      <th>coldstart</th>\n",
       "      <th>num_queries_per_context</th>\n",
       "      <th>total_generation_time_s</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_tokens_generated</th>\n",
       "      <th>avg_sentences_generated</th>\n",
       "      <th>avg_ATL</th>\n",
       "      <th>avg_GL</th>\n",
       "      <th>avg_TPS</th>\n",
       "      <th>avg_SPS</th>\n",
       "      <th>avg_energy_per_token</th>\n",
       "      <th>avg_energy_per_sentence</th>\n",
       "      <th>avg_exact_match</th>\n",
       "      <th>avg_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>long_context_qa</td>\n",
       "      <td>long_context</td>\n",
       "      <td>sglang</td>\n",
       "      <td>34.0776</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>34.2578</td>\n",
       "      <td>100</td>\n",
       "      <td>1614.200698</td>\n",
       "      <td>...</td>\n",
       "      <td>25.348</td>\n",
       "      <td>1.086</td>\n",
       "      <td>0.623155</td>\n",
       "      <td>3.228401</td>\n",
       "      <td>114.82412</td>\n",
       "      <td>2.01868</td>\n",
       "      <td>44.560479</td>\n",
       "      <td>216.584001</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.293496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  model_size_mb             task      scenario  \\\n",
       "0  Mistral-7B-Instruct-v0.3              0  long_context_qa  long_context   \n",
       "\n",
       "  backend  startup  ttft_sec  coldstart  num_queries_per_context  \\\n",
       "0  sglang  34.0776    0.1801    34.2578                      100   \n",
       "\n",
       "   total_generation_time_s  ...  avg_tokens_generated  \\\n",
       "0              1614.200698  ...                25.348   \n",
       "\n",
       "   avg_sentences_generated   avg_ATL    avg_GL    avg_TPS  avg_SPS  \\\n",
       "0                    1.086  0.623155  3.228401  114.82412  2.01868   \n",
       "\n",
       "   avg_energy_per_token  avg_energy_per_sentence  avg_exact_match  \\\n",
       "0             44.560479               216.584001            0.128   \n",
       "\n",
       "   avg_F1_score  \n",
       "0      0.293496  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"/home/ubuntu/fast_llm_inference/results_benchmark/run_report/sglang_long_context_qa_run_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f8fc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_size_mb</th>\n",
       "      <th>task</th>\n",
       "      <th>scenario</th>\n",
       "      <th>backend</th>\n",
       "      <th>startup</th>\n",
       "      <th>ttft_sec</th>\n",
       "      <th>coldstart</th>\n",
       "      <th>num_queries_per_context</th>\n",
       "      <th>total_generation_time_s</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_tokens_generated</th>\n",
       "      <th>avg_sentences_generated</th>\n",
       "      <th>avg_ATL</th>\n",
       "      <th>avg_GL</th>\n",
       "      <th>avg_TPS</th>\n",
       "      <th>avg_SPS</th>\n",
       "      <th>avg_energy_per_token</th>\n",
       "      <th>avg_energy_per_sentence</th>\n",
       "      <th>avg_exact_match</th>\n",
       "      <th>avg_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>long_context_qa</td>\n",
       "      <td>long_context</td>\n",
       "      <td>mii</td>\n",
       "      <td>226.5272</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>226.6647</td>\n",
       "      <td>100</td>\n",
       "      <td>5704.402642</td>\n",
       "      <td>...</td>\n",
       "      <td>19.714</td>\n",
       "      <td>1.208</td>\n",
       "      <td>1.985272</td>\n",
       "      <td>11.408805</td>\n",
       "      <td>2.67248</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>138.493149</td>\n",
       "      <td>773.620664</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.187467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  model_size_mb             task      scenario  \\\n",
       "0  Mistral-7B-Instruct-v0.3              0  long_context_qa  long_context   \n",
       "\n",
       "  backend   startup  ttft_sec  coldstart  num_queries_per_context  \\\n",
       "0     mii  226.5272    0.1376   226.6647                      100   \n",
       "\n",
       "   total_generation_time_s  ...  avg_tokens_generated  \\\n",
       "0              5704.402642  ...                19.714   \n",
       "\n",
       "   avg_sentences_generated   avg_ATL     avg_GL  avg_TPS  avg_SPS  \\\n",
       "0                    1.208  1.985272  11.408805  2.67248   0.3456   \n",
       "\n",
       "   avg_energy_per_token  avg_energy_per_sentence  avg_exact_match  \\\n",
       "0            138.493149               773.620664            0.066   \n",
       "\n",
       "   avg_F1_score  \n",
       "0      0.187467  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ccfb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(run_report)\n",
    "# Save the run report to a CSV file\n",
    "run_report_df = pd.DataFrame(run_report)\n",
    "run_report_df.to_csv(\"/home/ubuntu/fast_llm_inference/results_benchmark/run_report/mii2_long_context_qa_run_report.csv\", index=False)\n",
    "\n",
    "# Save the detailed report to a CSV file\n",
    "detailed_report_df = pd.DataFrame(detailed_report)\n",
    "detailed_report_df.to_csv(\"/home/ubuntu/fast_llm_inference/results_benchmark/details/mii2_long_context_qa_detailed_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6476083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_range</th>\n",
       "      <th>length</th>\n",
       "      <th>successful</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>generation_time</th>\n",
       "      <th>tokens_generated</th>\n",
       "      <th>sentences_generated</th>\n",
       "      <th>ATL</th>\n",
       "      <th>GL</th>\n",
       "      <th>TPS</th>\n",
       "      <th>SPS</th>\n",
       "      <th>energy_per_token</th>\n",
       "      <th>energy_per_sentence</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3k</td>\n",
       "      <td>3005</td>\n",
       "      <td>True</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>unanswerable</td>\n",
       "      <td>3606</td>\n",
       "      <td>1.833948</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611316</td>\n",
       "      <td>1.833948</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>42.645586</td>\n",
       "      <td>127.936757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3k</td>\n",
       "      <td>2385</td>\n",
       "      <td>True</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>BIBREF3, BIBREF4</td>\n",
       "      <td>varied from Maximum Entropy Classifiers (BIBRE...</td>\n",
       "      <td>1.844809</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204979</td>\n",
       "      <td>1.844809</td>\n",
       "      <td>4.88</td>\n",
       "      <td>0.54</td>\n",
       "      <td>14.299378</td>\n",
       "      <td>128.694402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3k</td>\n",
       "      <td>2413</td>\n",
       "      <td>True</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>1.284135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.284135</td>\n",
       "      <td>1.284135</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>89.581618</td>\n",
       "      <td>89.581618</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3k</td>\n",
       "      <td>2285</td>\n",
       "      <td>True</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>C2H</td>\n",
       "      <td>The focus of the study was on the reactive rad...</td>\n",
       "      <td>1.784524</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594841</td>\n",
       "      <td>1.784524</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>41.496310</td>\n",
       "      <td>124.488929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3k</td>\n",
       "      <td>1634</td>\n",
       "      <td>True</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>0.949298</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>66.223308</td>\n",
       "      <td>66.223308</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>32k</td>\n",
       "      <td>22936</td>\n",
       "      <td>False</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Internal Server Error</td>\n",
       "      <td>Ruth Honeywill</td>\n",
       "      <td>1.962817</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654272</td>\n",
       "      <td>1.962817</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>45.642245</td>\n",
       "      <td>136.926735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32k</td>\n",
       "      <td>17670</td>\n",
       "      <td>False</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Internal Server Error</td>\n",
       "      <td>She made a copy of the tape and gives it to he...</td>\n",
       "      <td>1.797285</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.599095</td>\n",
       "      <td>1.797285</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>41.793038</td>\n",
       "      <td>125.379115</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>32k</td>\n",
       "      <td>27912</td>\n",
       "      <td>False</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Internal Server Error</td>\n",
       "      <td>The nephew of Baron Frederick storms the castl...</td>\n",
       "      <td>1.863499</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621166</td>\n",
       "      <td>1.863499</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>43.332743</td>\n",
       "      <td>129.998229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>32k</td>\n",
       "      <td>25259</td>\n",
       "      <td>False</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Internal Server Error</td>\n",
       "      <td>key to the city</td>\n",
       "      <td>2.005213</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.668404</td>\n",
       "      <td>2.005213</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>46.628094</td>\n",
       "      <td>139.884281</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>32k</td>\n",
       "      <td>27907</td>\n",
       "      <td>False</td>\n",
       "      <td>### SYSTEM\\nYou are a question-answering assis...</td>\n",
       "      <td>Internal Server Error</td>\n",
       "      <td>Baron Frederick</td>\n",
       "      <td>2.044150</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681383</td>\n",
       "      <td>2.044150</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>47.533515</td>\n",
       "      <td>142.600544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_range  length  successful  \\\n",
       "0              3k    3005        True   \n",
       "1              3k    2385        True   \n",
       "2              3k    2413        True   \n",
       "3              3k    2285        True   \n",
       "4              3k    1634        True   \n",
       "..            ...     ...         ...   \n",
       "495           32k   22936       False   \n",
       "496           32k   17670       False   \n",
       "497           32k   27912       False   \n",
       "498           32k   25259       False   \n",
       "499           32k   27907       False   \n",
       "\n",
       "                                                prompt       generated_answer  \\\n",
       "0    ### SYSTEM\\nYou are a question-answering assis...           unanswerable   \n",
       "1    ### SYSTEM\\nYou are a question-answering assis...       BIBREF3, BIBREF4   \n",
       "2    ### SYSTEM\\nYou are a question-answering assis...                English   \n",
       "3    ### SYSTEM\\nYou are a question-answering assis...                    C2H   \n",
       "4    ### SYSTEM\\nYou are a question-answering assis...                    Yes   \n",
       "..                                                 ...                    ...   \n",
       "495  ### SYSTEM\\nYou are a question-answering assis...  Internal Server Error   \n",
       "496  ### SYSTEM\\nYou are a question-answering assis...  Internal Server Error   \n",
       "497  ### SYSTEM\\nYou are a question-answering assis...  Internal Server Error   \n",
       "498  ### SYSTEM\\nYou are a question-answering assis...  Internal Server Error   \n",
       "499  ### SYSTEM\\nYou are a question-answering assis...  Internal Server Error   \n",
       "\n",
       "                                      reference_answer  generation_time  \\\n",
       "0                                                 3606         1.833948   \n",
       "1    varied from Maximum Entropy Classifiers (BIBRE...         1.844809   \n",
       "2                                              English         1.284135   \n",
       "3    The focus of the study was on the reactive rad...         1.784524   \n",
       "4                                                  Yes         0.949298   \n",
       "..                                                 ...              ...   \n",
       "495                                     Ruth Honeywill         1.962817   \n",
       "496  She made a copy of the tape and gives it to he...         1.797285   \n",
       "497  The nephew of Baron Frederick storms the castl...         1.863499   \n",
       "498                                    key to the city         2.005213   \n",
       "499                                    Baron Frederick         2.044150   \n",
       "\n",
       "     tokens_generated  sentences_generated       ATL        GL   TPS   SPS  \\\n",
       "0                   3                    1  0.611316  1.833948  1.64  0.55   \n",
       "1                   9                    1  0.204979  1.844809  4.88  0.54   \n",
       "2                   1                    1  1.284135  1.284135  0.78  0.78   \n",
       "3                   3                    1  0.594841  1.784524  1.68  0.56   \n",
       "4                   1                    1  0.949298  0.949298  1.05  1.05   \n",
       "..                ...                  ...       ...       ...   ...   ...   \n",
       "495                 3                    1  0.654272  1.962817  1.53  0.51   \n",
       "496                 3                    1  0.599095  1.797285  1.67  0.56   \n",
       "497                 3                    1  0.621166  1.863499  1.61  0.54   \n",
       "498                 3                    1  0.668404  2.005213  1.50  0.50   \n",
       "499                 3                    1  0.681383  2.044150  1.47  0.49   \n",
       "\n",
       "     energy_per_token  energy_per_sentence  exact_match  F1_score  \n",
       "0           42.645586           127.936757            0  0.000000  \n",
       "1           14.299378           128.694402            0  0.057143  \n",
       "2           89.581618            89.581618            1  1.000000  \n",
       "3           41.496310           124.488929            0  0.200000  \n",
       "4           66.223308            66.223308            1  1.000000  \n",
       "..                ...                  ...          ...       ...  \n",
       "495         45.642245           136.926735            0  0.000000  \n",
       "496         41.793038           125.379115            0  0.000000  \n",
       "497         43.332743           129.998229            0  0.000000  \n",
       "498         46.628094           139.884281            0  0.000000  \n",
       "499         47.533515           142.600544            0  0.000000  \n",
       "\n",
       "[500 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastllm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
