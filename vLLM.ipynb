{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vllm serve meta-llama/Llama-3.1-8B --max-model-len 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import requests\n",
    "import json\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter Notebook\n",
    "import time\n",
    "\n",
    "# Load test data\n",
    "dataset = load_dataset(\"gigaword\", split=\"test[:100]\")  # Limit to 100 for fast eval\n",
    "\n",
    "# Initialize ROUGE metric\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_vllm(document, max_tokens=50):\n",
    "    prompt_template = (\n",
    "        \"You are an AI assistant specialized in summarizing news articles. \"\n",
    "        \"Summarize the following news sentence into a concise headline.\\n\\n\"\n",
    "\n",
    "        \"Here is an example:\\n\"\n",
    "        \"News: Japan 's nec corp. and UNK computer corp. of the united states said wednesday they had agreed to join forces in supercomputer sales.\\n\"\n",
    "        \"Headline: Nec UNK in computer sales tie-up\\n\\n\"\n",
    "\n",
    "        \"Now summarize the following news:\\n\\n\"\n",
    "\n",
    "        \"News: {document}\\n\\n\"\n",
    "        \"Headline:\"\n",
    "    )\n",
    "    \n",
    "    prompt = prompt_template.format(document=document)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Llama-3.1-8B\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": 0.3,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"http://localhost:8000/v1/completions\", json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        summary = result['choices'][0]['text'].strip()\n",
    "        return summary\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7284356cf7e3494d991c7c931c8bc69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing:   0%|          | 0/100 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM (Llama-3.1-8B) Summarization Results:\n",
      "\n",
      "Number of examples: 98\n",
      "\n",
      "Elapsed time: 271.17 s\n",
      "\n",
      "ROUGE Results:\n",
      "rouge1: 0.1682\n",
      "rouge2: 0.0582\n",
      "rougeL: 0.1498\n",
      "rougeLsum: 0.1538\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries and evaluate\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# tqdm around dataset loop with a description and progress bar\n",
    "for item in tqdm(dataset, desc=\"Summarizing\", unit=\"example\"):\n",
    "\n",
    "    doc = item['document']\n",
    "    ref_summary = item['summary']\n",
    "\n",
    "    pred_summary = summarize_with_vllm(doc)\n",
    "\n",
    "    if pred_summary:\n",
    "        references.append(ref_summary)\n",
    "        predictions.append(pred_summary)\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# Evaluate with ROUGE\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"vLLM (Llama-3.1-8B) Summarization Results:\")\n",
    "\n",
    "print(f\"\\nNumber of examples: {len(references)}\")\n",
    "print(f\"\\nElapsed time: {end - start:.2f} s\")\n",
    "\n",
    "print(\"\\nROUGE Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
